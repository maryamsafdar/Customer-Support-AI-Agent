
# Customer Support AI Agent (FastAPI + SQLite + Transformers + Streamlit)

**Goal:** A lightweight customer support agent that:
- Answers FAQs from a small SQLite knowledge base
- Falls back to a free Hugging Face Q&A model when unsure
- Creates a support ticket if confidence is low
- Exposes clean REST API endpoints for integration
- Optional Streamlit chat UI

---

## ğŸ§° Tech Stack (Free & Beginnerâ€‘Friendly)
- **Backend:** Python, FastAPI
- **DB:** SQLite (file-based, no setup)
- **AI:** Hugging Face `transformers` pipeline (`distilbert-base-uncased-distilled-squad`)
- **Frontend (optional):** Streamlit chat UI (or basic HTML/JS)

## ğŸ“ Project Structure
```text
customer-support-ai/
â”œâ”€ app/
â”‚  â”œâ”€ main.py              # FastAPI app + endpoints
â”‚  â”œâ”€ db.py                # SQLAlchemy engine/session
â”‚  â”œâ”€ models.py            # ORM models (FAQ, Ticket)
â”‚  â”œâ”€ schemas.py           # Pydantic request/response models
â”‚  â”œâ”€ faq_matcher.py       # Rule-based FAQ keyword matcher
â”‚  â”œâ”€ ai.py                # Hugging Face QA model wrapper
â”‚  â””â”€ seed_data.py         # Seed initial FAQs
â”œâ”€ data/
â”‚  â””â”€ support.db           # SQLite DB (autocreated)
â”œâ”€ frontend/
â”‚  â”œâ”€ streamlit_app.py     # Optional: chat-style UI
â”‚  â”œâ”€ index.html           # Optional: barebones HTML demo
â”‚  â”œâ”€ script.js            # Optional: fetch() -> /ask
â”‚  â””â”€ assets/
â”‚     â””â”€ styles.css        # Optional: minimal extra styling
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â””â”€ README.md
```

---
## ğŸ—“ï¸ 5â€‘Day Build Plan (Beginner â†’ Intermediate)

**Day 1 â€“ Project Setup**
1. Create a virtual environment and install dependencies.
2. Scaffold folders and files (see structure above).
3. Initialize FastAPI and SQLite.

**Day 2 â€“ FAQ System & Tickets**
1. Implement SQLAlchemy models for `FAQ` and `Ticket`.
2. Implement ruleâ€‘based FAQ matcher (keyword overlap).
3. Add CRUD endpoints to list/add FAQs and create/view tickets.

**Day 3 â€“ AI Answering**
1. Add Hugging Face QA pipeline (`distilbert-base-uncased-distilled-squad`).
2. Build context from FAQs; attempt AI answer when no FAQ match.
3. If AI confidence < threshold â‡’ create ticket automatically.

**Day 4 â€“ REST API**
- `/health`, `/ask`, `/tickets` (POST/GET), `/tickets/{id}`, `/faqs` (GET/POST)
- Enable CORS for simple HTML/JS frontends.

**Day 5 â€“ Optional Streamlit Frontend + Deploy**
1. Streamlit chat UI using `st.chat_message` (professional, clean).
2. Sidebar showing Open Tickets + manual ticket form.
3. Deploy options (free):
   - **Streamlit Cloud**: Deploy `frontend/streamlit_app.py` (standalone app).
   - **Hugging Face Spaces**: Deploy FastAPI backend (as `main:app`) **and/or** the Streamlit app.

---
## â–¶ï¸ Quick Start (Local)
```bash
# 0) (optional) python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 1) Seed example FAQs (creates ./data/support.db)
python -m app.seed_data

# 2) Run FastAPI backend
uvicorn app.main:app --reload --port 8000

# 3) (Option A) Minimal HTML demo
#     Open frontend/index.html in your browser (will call http://localhost:8000/ask)
#
# 3) (Option B) Streamlit chat UI (set BASE_URL in sidebar to your API URL)
streamlit run frontend/streamlit_app.py
```

**Environment variables (optional)**: copy `.env.example` â†’ `.env` and tune:
```
MODEL_NAME=distilbert-base-uncased-distilled-squad
AI_CONFIDENCE_THRESHOLD=0.45
```

---
## ğŸ”Œ REST API Endpoints

- `GET /health` â†’ `{ "status": "ok" }`
- `POST /ask`  
  **Body:** `{ "question": "string" }`  
  **Response:** `{ "answer": "â€¦", "source": "faq|ai|ticket", "score": number|null, "ticket_id": int|null }`

- `POST /tickets`  
  **Body:** `{ "question": "string", "email": "optional", "name": "optional" }`

- `GET /tickets` â†’ list tickets (most recent first)
- `GET /tickets/{id}` â†’ single ticket
- `GET /faqs` â†’ list FAQs
- `POST /faqs`  
  **Body:** `{ "question": "â€¦", "answer": "â€¦", "keywords": "comma,separated,words" }`

---
## ğŸ§ª How the Answering Works

1) **FAQ match first** using simple keyword overlap (fast + deterministic).  
2) **AI model second**: builds a context from all FAQs, tries Q&A pipeline.  
3) **Ticket fallback** when AI confidence < `AI_CONFIDENCE_THRESHOLD`.

> Tip: Improve FAQ coverage & keywords to reduce tickets and AI load.

---
## ğŸ¨ Professional Streamlit UI

- Clean, chatâ€‘style layout with avatars and subtle separators
- Persistent session history
- Sidebar: API Base URL, Open Tickets, Manual Ticket creation
- Handles loading states and error messages gracefully

---
## â˜ï¸ Deploy (Free)

### Option 1: Streamlit Cloud
1. Push this folder to GitHub.
2. On Streamlit Cloud, create a new app â†’ point to `frontend/streamlit_app.py`.
3. In the sidebar of the deployed app, set **API Base URL** to your FastAPI endpoint.

### Option 2: Hugging Face Spaces
- **Backend Space (FastAPI)**:
  - Create a Space â†’ choose *Docker* or *SDK* â†’ `fastapi` template.
  - Set `app.main:app` as the entry point (or use provided HF template).
- **Frontend Space (Streamlit)**:
  - Create a Space â†’ `streamlit` template â†’ set `frontend/streamlit_app.py`.
  - Point the sidebar **API Base URL** to your backend Space URL.

---
## âš™ï¸ Notes

- First run will download the QA model (~260MB). Subsequent runs are cached.
- Everything runs on CPU; no GPU required.
- You can later swap SQLite â†’ Postgres and replace the model with a better one.
